Practical No. 5 ‚Äì Implementation of Convolutional Neural Network (CNN)
Aim:

To implement a Convolutional Neural Network (CNN) using PyTorch for image classification on the MNIST or CIFAR-10 dataset, and compare its performance with a simple Multilayer Perceptron (MLP).

*************************************************************************************************

üü¶ A) Code Theory (what the script does)
1. Dataset loading & preprocessing

mnist.load_data() loads train/test splits of 28√ó28 grayscale digit images.

Reshape to (N, 28, 28, 1) and scale pixel values to [0,1] by dividing by 255.

Labels converted to one-hot vectors with to_categorical for categorical cross-entropy.

2. Data augmentation (ImageDataGenerator)

ImageDataGenerator applies random small transformations (rotation, shifts, zoom).

datagen.flow(x_train, y_train, batch_size) produces augmented batches each epoch.

Purpose: increase effective training data variety to reduce overfitting and improve generalization.

3. CNN model architecture

Two convolutional blocks:

Conv2D(32,3x3) + ReLU ‚Üí MaxPool(2x2)

Conv2D(64,3x3) + ReLU ‚Üí MaxPool(2x2)

Flatten ‚Üí Dense(64, ReLU) ‚Üí Dense(10, softmax)

CNNs learn local spatial patterns (edges ‚Üí shapes) and are spatially invariant because of convolutions and pooling.

4. MLP (fully-connected) model

Flatten 28√ó28 ‚Üí Dense(256, ReLU) ‚Üí Dense(128, ReLU) ‚Üí Dense(10, softmax)

MLP treats each pixel independently ‚Äî no built-in spatial inductive bias ‚Äî so it needs more parameters to learn spatial patterns that CNN learns more efficiently.

5. Compilation & training

compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

Adam: adaptive learning-rate optimizer.

Categorical cross-entropy: appropriate for one-hot multi-class classification.

cnn.fit(datagen.flow(...), epochs=5, validation_data=(x_test,y_test)) uses augmentation during training; validation uses original test data.

mlp.fit(x_train, y_train, ...) trains MLP without augmentation.

6. Evaluation

model.evaluate(x_test, y_test) computes loss and accuracy on held-out test set.

üü© B) Output Theory (what the numbers and curves mean)
1. Training logs (per epoch)

Each epoch prints training accuracy & loss and validation accuracy & loss. Example observations from your run:

CNN reached training accuracy ‚âà 98% and validation accuracy ‚âà 99% by epoch 5.

MLP reached training accuracy ‚âà 98.9% and validation accuracy ‚âà 97.7% by epoch 5.

Interpretation:

Train accuracy measures how well the model fits the training data.

Val/test accuracy measures generalization to unseen data.

When train acc ‚â´ val acc ‚Üí overfitting. Here both models generalize well, but CNN generalizes better.

2. Why CNN outperforms MLP on image data

Spatial locality & parameter sharing: Conv layers reuse kernels across the image, so CNN learns translation-invariant features with fewer parameters.

Inductive bias: Convolutions match the structure of images (local correlations), so CNNs generalize better with less data/parameters.

Your results: CNN test accuracy ‚âà 0.9898, MLP ‚âà 0.9774 ‚Äî expected: CNN slightly better on MNIST.

3. Role of augmentation

The CNN was trained with augmentation (datagen) which helps model see varied examples ‚Üí improves robustness and likely raises validation accuracy.

If MLP trained with same augmentation it might improve, but convolutional architectures benefit more from augmentation due to spatial features.

4. Loss vs Accuracy

Low validation loss + high validation accuracy ‚Üí confident, well-generalized predictions.

If validation loss were to increase while accuracy stays high, that could suggest uncertainty in predicted probability calibration ‚Äî but not an issue here.

5. What to watch for (diagnostics)

If training accuracy is high but test accuracy falls, that signals overfitting ‚Äî apply regularization, dropout, augmentation, or reduce model capacity.

If both accuracies are low, model underfits ‚Äî increase capacity, train longer, or tune optimizer/hyperparams.

******************************************************************************************************

Theory:
1Ô∏è‚É£ Introduction:

A Convolutional Neural Network (CNN) is a deep learning model specifically designed for analyzing visual data such as images.
Unlike traditional MLPs, CNNs automatically learn spatial hierarchies of features ‚Äî edges, textures, shapes ‚Äî by using convolutional filters.

CNNs are highly effective for tasks like image recognition, object detection, and image classification.

2Ô∏è‚É£ Why CNN instead of MLP?

MLP treats all pixels independently and ignores spatial relationships.

CNN uses convolutional filters to extract local features like edges and corners.

CNNs have fewer parameters due to weight sharing and local connectivity.

CNNs generalize better and are computationally efficient for image data.

3Ô∏è‚É£ Architecture of a CNN:

A typical CNN includes the following layers:

Input Layer:

Accepts image data (e.g., 28√ó28 grayscale image).

Convolutional Layer (Conv Layer):

Performs convolution between the input and learnable filters (kernels).

********************************

Detailed explanation of key functions used (one-line each)

1.mnist.load_data() ‚Äî downloads and returns train/test splits.

2.reshape(...,1) ‚Äî adds channel dimension for Conv2D.

3./ 255 ‚Äî scale to [0,1].

4.to_categorical() ‚Äî convert integer labels to one-hot vectors.

5.ImageDataGenerator(...) ‚Äî specify augmentation transforms.

6.datagen.flow(x_train, y_train, batch_size=64) ‚Äî yields augmented batches for training.

7.Conv2D(filters, kernel, activation) ‚Äî convolution layer producing feature maps.

8.MaxPooling2D(pool) ‚Äî downsample spatial dimensions.

9.Flatten() ‚Äî convert 3D feature maps to 1D vector.

10.Dense(units, activation) ‚Äî fully connected layer.

11.softmax ‚Äî converts logits to probabilities that sum to 1.

12.compile(optimizer, loss) ‚Äî configure training: optimizer and loss.

13.fit(...) ‚Äî train the model.

14.evaluate(...) ‚Äî compute metrics on test set.

**********************************



Detects features such as edges and corners.

Activation Function (ReLU):

Adds non-linearity to the network.

ReLU(x) = max(0, x).

Pooling Layer (Max Pooling):

Reduces spatial size and computation.

Example: 2√ó2 max pooling reduces feature map size by half.

Fully Connected (FC) Layer:

Flattens features and maps them to the output classes.

Output Layer:

Uses Softmax for multi-class classification.

4Ô∏è‚É£ Advantages of CNNs:

Automatically learn relevant image features.

Reduce number of parameters through weight sharing.

Provide translation and scale invariance.

Achieve higher accuracy than fully connected networks for visual data.

**Algorithm:

1.Import Libraries:
-Import torch, torchvision, torch.nn, torch.optim, and matplotlib.

2.Load Dataset:

-Use MNIST or CIFAR-10 dataset.

-Normalize pixel values and create DataLoader objects for training and testing.

3.Define CNN Architecture:

-Add two convolutional layers (Conv2D) with ReLU and MaxPooling.

-Add fully connected layers to classify into output classes.

-Example:

Conv2d(1, 32, kernel_size=3)
ReLU
MaxPool2d(2)
Conv2d(32, 64, kernel_size=3)
ReLU
MaxPool2d(2)
Flatten
Linear ‚Üí ReLU ‚Üí Linear ‚Üí Output


4.Define Loss and Optimizer:

-Loss: CrossEntropyLoss

-Optimizer: Adam or SGD

5.Training Phase:

-For each epoch:

	-Forward pass: Compute output and loss.

	-Backward pass: Compute gradients.

	-Update weights with optimizer.

	-Record training loss and accuracy.

6.Testing Phase:

-Evaluate the model on the test dataset.

-Compute test loss and accuracy.

7.Plot Results:

-Plot training & test loss vs. epochs.

-Plot training & test accuracy vs. epochs.

8.Compare Results:

Compare CNN‚Äôs performance with a simple MLP.


Result:

CNN successfully classifies handwritten digits or images with high accuracy.

Loss decreases and accuracy increases with each epoch.

Example result:

Epoch 5/5: Train Loss = 0.042, Train Acc = 99.15%, Test Acc = 98.75%


CNN shows higher accuracy and faster convergence than MLP due to feature extraction via convolutional layers.

Conclusion:

CNN automatically learns spatial and local features of images, unlike MLP which relies on flattened input.

The use of convolution and pooling layers reduces parameters and improves efficiency.

The experiment proves that CNNs achieve better accuracy and generalization for image classification tasks.

CNNs form the foundation for advanced models like ResNet, VGG, and Inception networks.

What to say in viva ‚Äî short, memorized answers

Q: Why normalize images?
A: To scale inputs in a similar range so training is numerically stable and converges faster.

Q: Why use softmax + categorical_crossentropy?
A: Softmax produces class probabilities; categorical cross-entropy measures the distance between predicted distribution and true one-hot label.

Q: Why does CNN perform better than MLP on images?
A: CNN uses local receptive fields and weight sharing (filters) to learn spatial features efficiently; MLP ignores spatial structure.

Q: What does ImageDataGenerator do?**
A: It applies random transformations to training images each epoch (augmentation) to improve generalization.

Q: Why use Adam optimizer?**
A: Adam adapts learning rates per parameter and includes momentum ‚Äî often converges faster and requires little tuning.

Q: What is overfitting and how to avoid it?**
A: Overfitting is when model fits training data too well but fails on new data. Avoid with augmentation, dropout, L2, early stopping.

Q: What is a filter in Conv2D?**
A: A small matrix (kernel) convolved with the image to detect patterns like edges and textures.

Q: What is pooling for?**
A: Reduces spatial dimensions and makes features robust to small translations.

